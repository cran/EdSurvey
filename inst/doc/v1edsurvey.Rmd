---
title: 'Using EdSurvey `r packageVersion("EdSurvey")` to Analyze NAEP Data: An Illustration of Analyzing NAEP Primer'
author: Developed by Paul Bailey, Ahmad Emad, Michael Lee, Ting Zhang, Qingshu Xie, & Jiao Yu\footnote{This publication was prepared for NCES under Contract No. ED-IES-12-D-0002 with American Institutes for Research. Mention of trade names, commercial products, or organizations does not imply endorsement by the U.S. Government.} \footnote{The authors would like to thank Young Yee Kim and Dan Sherman for reviewing this document, as well as Jiayi Li and Fei Liu for conducting quality control tests to verify the functions in this document.}
date: '`r format(Sys.Date(),"%B %d, %Y")`'
output:
  pdf_document:
    fig_caption: yes
    number_sections: no
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{1. Introduction to EdSurvey}
  \usepackage[utf8]{inputenc}
---
  
# Overview of the EdSurvey Package
  
National Assessment of Educational Progress (NAEP) data sets from the National Center for Education Statistics (NCES) require special statistical methods to analyze due to their scope and complexity. The `EdSurvey` package gives users functions to perform analyses that account for both complex sample survey design and the use of plausible values.

The `EdSurvey` package also seamlessly takes advantage of the `LaF` package to read in data only when it is required for an analysis. Users with computers that have insufficient memory to read in the entire NAEP data sets can still do analyses without having to write special code to read in just the appropriate variables. This is all taken care of directly in the `EdSurvey` package---behind the scenes and without special tuning by the user.

## Vignette outline

This vignette will describe the basics of using the `EdSurvey` package for analysis of NAEP data as follows:

* Preparing the R environment for processing
* Accessing details about data of interest
* Creating summary tables using the `edsurveyTable` function
* Computing the percentages of students by achievement levels with the `achievementLevels` function
* Running linear regression models using the `lm.sdf` function
* Correlating variables with the `cor.sdf` function
* Retrieving data for manipulation by the user using the `getData` function

## Additional resources

There are two supplementary vignettes in the package to assist in analyzing NCES data. *Using the getData Function in EdSurvey `r packageVersion(quote(EdSurvey))` to Manipulate the NAEP Primer Data* describes using the `EdSurvey` package in situations where extensive data manipulation is performed before analysis. The other, *Using the EdSurvey Package to Analyze NAEP Data With and Without Accommodations*, provides an overview of NAEP data with accommodations and describes methods used to analyze this data.

***

## Vignette notation

This vignette displays examples using notation for R console input and output. Console input will be displayed within a grey box:

```{r input code}
inputCode <- c(2,"neat")
```

R console output will be displayed next to a double hash mark (`##`). Here is an example where the user types "`inputCode`" into the console and the code output R gives after the double hash marks:

```{r input output}
inputCode
```

## Software requirements

Unless you already have R version 3.2.0 or later,  install the latest R version---which is available online at [https://cran.r-project.org/](https://cran.r-project.org/). Users also may want to install RStudio desktop which has an interface that many find easier to follow. RStudio is available online at  [https://www.rstudio.com/products/rstudio/download/](https://www.rstudio.com/products/rstudio/download/).

# Setting up the Environment for Analysis of NCES Data

## Installing and Loading EdSurvey

Inside R, run the following command to install `EdSurvey` as well as its package dependencies:

```{r code options, echo=FALSE}
options(width=85)
```

```{r source package, eval=FALSE}
install.packages("EdSurvey")
```
Once the package is successfully installed, `EdSurvey` can be loaded with the following command:

```{r load package}
library(EdSurvey)
```

## Reading in data

The first step to running an analysis is reading in the data. This is done using `EdSurvey`'s `readNAEP` function.

##### Vignette sample NCES data set:
To follow along with this vignette, load the NAEP Primer data set `M36NT2PM` and assign it the name  `sdf` with this call:
  
```{r readNAEP, source package}
sdf <- readNAEP(system.file("extdata/data", "M36NT2PM.dat", package="NAEPprimer"))
```

Note that this command uses a somewhat unusual way of identifying a file path (the `system.file` function). Because the Primer data is bundled with the NAEPprimer package, the `system.file` function finds it regardless of where the package was installed on the machine. All other data sets will have to be referred to by their system path.

##### NCES data set

To load a unique NCES data set for analysis, select the pathway to the DAT file in the NAEP assessment folder, which needs to be in the NCES standard folder directory titled `/Data`:
```{r readNAEPvig, eval=FALSE}
sdf2 <- readNAEP(filepath='//.../Data/file.dat')
```

Note that the function recognizes the naming convention used by NCES for NAEP file names to determine which sample design and assessment information is attached to the resulting `edsurvey.data.frame`. The `readNAEP` function transparently accesses the necessary sample information and silently attaches it to the data.[^noteEDS]

[^noteEDS]: The `EdSurvey` package uses the `.fr2` file in the `/Select/Parms` folder to assign this information to the `edsurvey.data.frame`.

Both student and school data from a NCES data set can be analyzed and merged after loading the data into the R working environment. The `readNAEP` function is built to connect with the student data file, but it silently holds file formatting for the school data set when read. More details on retrieving school variables for analysis will be outlined in this vignette with the `getData` function.

## Getting to know the data format
There are several ways to get information about an `edsurvey.data.frame`. To get general data information, simply call print by typing the name of the `data.frame` object (i.e. `sdf`) in the console.

```{r print SDF}
sdf
```

Some of the basic functions that work on a `data.frame`, such as `dim`, `nrow` and `ncol`, also work on an `edsurvey.data.frame`.[^whatisdim] They help to check the dimensions of `sdf`.

[^whatisdim]:Use ?*function* in the R console to view documentation on base R and `EdSurvey` package functions. For example `?gsub` or `?lm.sdf`.


```{r data.frame like, warning=FALSE}
dim(x=sdf)
nrow(x=sdf)
ncol(x=sdf)
```

The `names` function can be used to list all variable names in the data:

```{r names}
names(x=sdf)
```

To conduct a more powerful search of NAEP data variables, use the `searchSDF` function, which returns variable names and labels from an `edsurvey.data.frame` based on a character string. The user can specify which data source (either "student" or "school") the user would like to search. For example, this call to `searchSDF` searches for the character string `"book"` in the `edsurvey.data.frame` and specifies the `fileformat` to search the student data file:

```{r searchSDF}
searchSDF(string="book", data=sdf, fileFormat="student")
```

The levels and labels for each variables search via `searchSDF()` can also be returned by setting `levels=TRUE`:

```{r searchSDF levels}
searchSDF(string="book", data=sdf, fileFormat="student", levels=TRUE)
```

To return the levels and labels for a particular variable use `levelsSDF()`:

```{r levelsSDF levels}
levelsSDF(varnames="b017451", data=sdf)
```

Basic information about plausible values and weights in an `edsurvey.data.frame` can be seen in the `print` function. The variables associated with plausible values and weights can be seen from the `showPlausibleValues` and `showWeights` functions, respectively, when the `verbose` argument is set to `TRUE`.

```{r pv and weights}
showPlausibleValues(data=sdf, verbose=TRUE)
showWeights(data=sdf, verbose=TRUE)
```

### Removing Special Values

The EdSurvey package uses listwise deletion to remove special values in all of it's analyses by default. For example, in the NAEP primer data the omitted levels are returned when `print(sdf)` is called: `Omitted Levels: 'Multiple', 'NA', 'Omitted'`. By default these levels are excluded via listwise deletion. To use a different method, such as pairwise deletion, set `defaultConditions=FALSE` when running your analysis.

# Making a Table

Summary tables can be created in the `EdSurvey` package using the `edsurveyTable` function. A call to `edsurveyTable`[^helpedsurveyTable] with two variables, `dsex` and `b017451`, creates a table that shows the number, percentage and NAEP mathematics performance scale scores of eighth-grade students by gender and frequency of talk about studies at home. Percentages add up to 100 within each gender. 

[^helpedsurveyTable]: Consult the appendix or `?edsurveyTable` for details on default `edsurveyTable` arguments.

```{r edsurveyTable, cache=FALSE, warning=FALSE}
es1 <- edsurveyTable(composite ~ dsex + b017451, data=sdf, 
                     jrrIMax=1, varMethod="jackknife")
```

The `edsurveyTable` created above is saved as the object `es1`, and the resulting table can be displayed by printing

```{r, eval=FALSE}
es1$data
```
```{r edsurveyTable kable, results='asis', echo=FALSE}
knitr::kable(x=es1$data, digits=7, row.names=FALSE, caption="es1")
```

Note that we used the argument `jrrIMax` to indicate the maximum number of plausible values to be included when calculating sampling variance in the computation of standard error of estimates, such as

* estimated scale scores,
* achievement levels, and
* regression analysis of student performance using jackknife variance estimation.

The default estimation option, `jrrIMax=1`, uses the sampling variance from the first plausible value as the component for sampling variance in the computation of the standard errors of estimates involving plausible values with the jackknife variance estimation method, as seen in the next example. The argument `jrrIMax` can be omitted to select the default. Higher values of `jrrIMax` leads to longer computing times but more accurate error estimates.[^helplmsdf] An alternative is to set `jrrIMax=Inf` to obtain the ideal estimation with jackknife method.

The function also features variance estimation using the Taylor series method. By setting `varmethod="Taylor"`, the same `edsurveyTable` call used in the previous example can return results using Taylor series variance estimation:

```{r edsurveyTable taylor, cache=FALSE, warning=FALSE}
es1t <- edsurveyTable(composite ~ dsex + b017451, data=sdf, 
                      jrrIMax=1, varMethod="Taylor")
```
```{r, eval=FALSE}
es1t$data
```
```{r edsurveyTable Taylor kable, results='asis', echo=FALSE}
knitr::kable(x=es1t$data, digits=7, row.names=FALSE, caption="es1t")
```

[^helplmsdf]: See the documentation for `lm.sdf` for details on the variance calculation.

If the percentages do not add to up to 100 at the desired level, an adjustment can be made in the `pctAggregationLevel` argument to change to the level that they need to add up to 100.

Calculation of means and standard errors require computation time that the user may not want to wait for. If you wish to simply see a table of the levels and the *N* sizes, you can set the `returnMeans` and `returnSepct` arguments to `FALSE` to omit those columns as follows:

```{r edsurveyTable1b, cache=FALSE, warning=FALSE}
es1b <- edsurveyTable(composite ~ dsex + b017451, data=sdf, jrrIMax=1,
                      returnMeans=FALSE, returnSepct=FALSE)
```

In the `edsurveyTable` created above, the resulting table can be displayed by printing the object.

```{r, eval=FALSE}
es1b
```
```{r edsurveyTable1b kable, results='asis', echo=FALSE}
knitr::kable(x=es1b$data, digits=7, row.names=FALSE, caption="es1b")
```

For more details on the arguments in the `edsurveyTable` function, look at the examples using

```{r, eval=FALSE}
?edsurveyTable
```

# Achievement Level Analysis

The `achievementLevels` function[^helpAL] computes the percentages of students by achievement levels defined by NAEP. Each NAEP data set's unique set of cut points for achievement levels (defined as ***Basic***, ***Proficient***, and ***Advanced***) is provided in the `EdSurvey` package. They can be accessed using the `showCutPoints` function:

[^helpAL]: Consult the appendix or `?achievementLevels` for details on default `achievementLevels` arguments.

```{r showCutPoints}
showCutPoints(data=sdf)
```

The `achievementLevels` function applies appropriate weights and variance estimation method for each `edsurvey.data.frame`, with several arguments for customizing the aggregation and output of the analysis results. Namely, by using these optional arguments, users can choose  to generate the percentage of students performing at each achievement level (*discrete*), at or above each achievement level (*cumulative*), calculate the percentage distribution of students by achievement levels (discrete or cumulative) and selected characteristics (specified in `aggregateBy`), and compute the percentage distribution of students by selected characteristics *within* a specific achievement level.

The `achievementLevels` function can produce statistics by both discrete and cumulative achievement levels. By default, the `achivementLevels` function only produces the results by discrete achievement levels; when the `returnCumulative` argument is set to `TRUE`, the function generates results by both discrete and cumulative achievement levels.

To compute overall results by achievement levels, use the NAEP data set's default plausible values in the `achievementVars` argument; in this case, they are the 5 or 20 plausible values for the subject composite scale.

```{r overall achievement levels}
aLev0 <- achievementLevels(achievementVars=c("composite"),
                           data=sdf, returnCumulative=TRUE)
```
```{r, eval=FALSE}
aLev0$discrete
```
```{r aL0 kable, results='asis', echo=FALSE}
knitr::kable(x=aLev0$discrete, digits=7, row.names=FALSE, caption="aLev0$discrete")
```

In the next example, the plausible values for `composite` and the variable `dsex` are used to calculate the achievement levels, which are aggregated by the variable `dsex` using `aggregateBy`.

```{r achievementLevels dsex}
aLev1 <- achievementLevels(achievementVars=c("composite", "dsex"), aggregateBy="dsex",
                           data=sdf, returnCumulative=TRUE)
```
```{r, eval=FALSE}
aLev1$discrete
```
```{r aL1 kable, results='asis', echo=FALSE}
knitr::kable(x=aLev1$discrete, digits=7, row.names=FALSE, caption="aLev1$discrete")
```

Note that each level of the `dsex` variable aggregates to 100 for the results by discrete achievement levels. The object `aLev1` created in this call to `achievementLevels` is a `list` with two `data.frame`s: one for the discrete results and the other cumulative. In the previously described code, only the discrete levels are shown using `aLev1$discrete`. To show the cumulative results, change the specified `data.frame`. For example:

```{r, eval=FALSE}
aLev1$cumulative
```
```{r aL1 kable 2, results='asis', echo=FALSE}
knitr::kable(x=aLev1$cumulative, digits=7, row.names=FALSE, caption="aLev1$cumulative")
```

The `aggregateBy` argument sums the percentage of students by discrete achievement level up to 100 at the most disaggregated level specified by the analytical variables, as well as determining the order of aggregation. For example, when `dsex` and `iep` are used for analysis, `aggregateBy=c("dsex", "iep")` and `aggregateBy=c("iep", "dsex")` produce the same percentages, but arrange the results in different ways, depending on order in the argument. When using `aggregateBy=c("dsex", "iep")`, the percentages add up to 100 within each category of `iep` for each category of `dsex`, respectively; when using `aggregateBy=c("iep", "dsex")`, the percentages add up to 100 within each category of `dsex` for each category of `iep`, respectively.

```{r achievementLevels2}
achievementLevels(achievementVars=c("composite", "dsex", "iep"), aggregateBy=c("dsex", "iep"),
                  data=sdf)
achievementLevels(achievementVars=c("composite", "dsex", "iep"), aggregateBy=c("iep", "dsex"),
                  data=sdf)
```

Notice that each unique value pair of the two variables (i.e., Yes + Male or No + Female) sums to 100 due to `aggregateBy`.

*NOTE:* It is not appropriate to aggregate the results by only one variable when more than one variables are used in the analysis. The same variables used in the analysis need to be used in the argument `aggregateBy()` and their order can be changed to obtain desired results.

The `achievementLevels` function can also compute the percentage of students by selected characteristics within a specific achievement level. The object `aLev2` presents the percentage of students by sex within each achievement level (i.e., within each discrete and cumulative levels).

```{r aLev2 characteristics, cache=FALSE, warning=FALSE}
aLev2 <- achievementLevels(achievementVars=c("composite", "dsex"), aggregateBy="composite",
                           data=sdf, returnCumulative=TRUE)
aLev2$discrete
aLev2$cumulative
```

The percentage of students within a specific achievement level can be aggregated by one or more variables. For example, the percentage of students classified as ELL (`lep`) is aggregated by `dsex` within each achievement level:

```{r aLev3 three-way, cache=FALSE, warning=FALSE}
aLev3 <- achievementLevels(achievementVars=c("composite", "dsex", "lep"),
                           aggregateBy=c("dsex", "composite"),
                           data=sdf,
                           returnCumulative=TRUE)
aLev3$discrete
aLev3$cumulative
```

Finally, users can set unique cut points that override the standard values in the `EdSurvey` package using the `cutpoints` argument. In the example to follow, `aLev1` uses the standard cut points of `c(262,299,333)` as shown in `showCutPoints` earlier, while `aLev4` uses `cutpoints=c(267,299,333)`, resulting in a higher threshold to reach the ***Basic*** category but leaving ***Proficient*** and ***Advanced*** unchanged:

```{r aLev4 cutpoints, cache=FALSE, warning=FALSE}
aLev4 <- achievementLevels(achievementVars=c("composite", "dsex"),
                           aggregateBy="dsex",
                           data=sdf,
                           cutpoints=c(267, 299, 333),
                           returnCumulative=TRUE)

aLev4$discrete
aLev1$discrete
```

Changing the cut point for a particular achievement level will result in different distributions of student achievement. Notice that  labels for the levels based on user-defined cut points are distinct from those based on NAEP-defined cut points; instead, labels are based on the range of values in the `cutpoints` argument.

# Regression Analysis

After the data is read in with the `EdSurvey` package, a linear model can be fit to fully account for the complex sample design used for the NAEP data by using `lm.sdf`.

Note that the option `jrrIMax` is left out in the following example; therefore, the default jackknife variance estimator is used. Also, note that an explicit weight variable is not set, so the `lm.sdf` function uses `origwt`, the default, as the weight for the full sample in the analysis.

The data is read in and analyzed by the `lm.sdf` function--in this case, `dsex`, `b017451`, the five plausible values for `composite`, and the full sample weight `origwt`. By default, variance is estimated using the jackknife method, so the following call reads in the jackknife replicate weights:[^helplmsdf2]

[^helplmsdf2]: Consult the appendix or `?lm.sdf` for details on default `lm.sdf` arguments.

```{r lm, cache=FALSE, warning=FALSE}
lm1 <- lm.sdf(composite ~ dsex + b017451, data=sdf)
summary(lm1)
```

After the regression is run, the data is automatically removed from memory. By default, `lm.sdf` uses "treatment contrasts," where one level is dropped from the regression. This cannot be changed, but the omitted and comparison group can be changed with the `relevels` argument. In the following example, "Female" is omitted from the analysis for the variable `dsex`:

```{r lmf, cache=FALSE, warning=FALSE}
lm1f <- lm.sdf(composite ~ dsex + b017451, data=sdf,
               relevels=list(dsex="Female"))
summary(lm1f)
```

Note that the coefficient on `dsex` changed from negative in the previous run to positive of the exactly same magnitude, whereas none of the other coefficients (aside from the intercept) changed at all--this is the expected result. The change is due to the switch of the reference gender from "Male" in the first regression model to "Female" in the second regression model. The `lm.sdf` function features variance estimation using both the jackknife and Taylor series variance estimation methods by setting the `varMethod` argument to the desired technique.


# Correlation Analysis

The `EdSurvey` package features multiple correlation methods for data exploration and analysis that fully accounts for the complex sample design in NAEP data by using the `cor.sdf` function.[^helpcorsdf] This includes the following correlation procedures:

[^helpcorsdf]: Consult the appendix or `?cor.sdf` for details on default `cor.sdf` arguments.


* Pearson product-moment correlations for continuous variables,
* Spearman rank correlation for ranked variables,
* Polyserial correlations for one categorical and one continuous variable,
* Polychoric correlations for two categorical variables, and
* Correlations among plausible values of the subject scales and subscales (marginal correlation coefficients, which uses Pearson type).

In the following example, `b013801`, `t088001`, and the full sample weight `origwt` are read in to calculate the correlation using the Pearson method. Similar to other `EdSurvey` functions, the data is removed automatically from memory after the correlation is run.

```{r cor pearson, cache=FALSE, warning=FALSE}
cor_pearson <- cor.sdf(x="b013801", y="t088001", data=sdf, 
                       method="Pearson", weightVar="origwt")
```

It's important to take note of the order of levels to ensure that correlations are functioning as intended. Printing a correlation object will provide a condensed summary of correlation details and the order of levels for each variable:

```{r cor, warning=FALSE}
cor_pearson
```

Variables in `cor.sdf` can be recoded and reordered. Variable levels and values can be redefined given desired specifications. For example, `b017451` and `t088001` are correlated using the Pearson method, with the levels `"2 or 3 times a week"` and `"Every day"` of the variable `b017451` being *recoded* to `"Frequently"` within a list of lists in the `recode` argument:

```{r cor recode, cache=FALSE, warning=FALSE}
cor_recode <- cor.sdf(x="b017451",y="t088001", data=sdf, 
                      method="Pearson", weightVar="origwt",
                      recode=list(b017451=list(from=c("2 or 3 times a week",
                                                      "Every day"),
                                               to=c("Frequently"))))
cor_recode
```

Recoding can be useful when a level is very thinly populated (so that it might merit combination with another level) or when changing the value label to something more appropriate for a particular analysis.

The variables `b017451` and `t088001` are correlated using the Pearson method in the following example, with the variable `t088001`'s values `"Less than 3 hours","3-4.9 hours","5-6.9 hours","7 hours or more"` being *reordered* to `"7 hours or more","5-6.9 hours","3-4.9 hours","Less than 3 hours"` within a list:

```{r cor reorder, cache=FALSE, warning=FALSE}
cor_reorder <- cor.sdf(x="b017451",y="t088001", data=sdf, 
                       method="Pearson", weightVar="origwt",
                       reorder=list(t088001=c("7 hours or more","5-6.9 hours",
                                              "3-4.9 hours","Less than 3 hours")))
cor_reorder
```

Changing the order of levels might be useful to modify a variable that is out of order or when reversing the orientation of a series. The `reorder` argument is also suitable when implemented in conjunction with recoded levels.

*NOTE:* As an alternative, recoding also can be completed within `getData`, a function detailed later in the vignette. To see additional examples of recoding and reordering, use `?cor.sdf` in the R console.

The **Marginal Correlation Coefficient** among plausible values of the subject scales and subscales can be calculated using the `cor.sdf` function and the Pearson method. The subject subscales `num_oper` and `algebra` are correlated in this example:

```{r cor marginal, cache=FALSE, warning=FALSE}
cor3_mcc <- cor.sdf(x="num_oper", y="algebra", data=sdf, method="Pearson")
cor3_mcc
```

Use the `showPlausibleValues` function to return the plausible values of an `edsurvey.data.frame` for use in calculating the correlation coefficients between subject scales or subscales.

The `cor.sdf` function features multiple methods for data exploration and analysis using correlations. The following example shows the differences in correlation coefficients among the Pearson, Spearman, and Polychoric methods using a `subset`[^subsetnote] of the `edsurvey.data.frame` data where `dsex == 1` (saved as the `sdf_dnf` object), `b017451`, `pared`, and the full sample weight `origwt`:

[^subsetnote]: `subset` will be further detailed in this vignette, or use `?subset` to access function documentation.


```{r cor continuous, cache=FALSE, warning=FALSE}
sdf_dnf <- subset(sdf, dsex == 1)
cor_pearson <- cor.sdf(x="b017451", y="pared", data=sdf_dnf, 
                       method="Pearson", weightVar="origwt")
cor_spearman <- cor.sdf(x="b017451", y="pared", data=sdf_dnf, 
                        method="Spearman", weightVar="origwt")
cor_polychoric <- cor.sdf(x="b017451", y="pared", data=sdf_dnf, 
                          method="Polychoric", weightVar="origwt")
```

```{r cor comparison, warning=FALSE}
cbind(Correlation=c(Pearson=cor_pearson$correlation,
                    Spearman=cor_spearman$correlation,
                    Polychoric=cor_polychoric$correlation))
```

Plausible values for subject scales and subscales also can be correlated with variables using the `cor.sdf` function. In this case, the five plausible values for `composite`, the variable `b017451`, and the full sample weight `origwt` are read in to calculate the correlation coefficients using the Pearson, Spearman, and Polyserial methods:

```{r cor categorical, cache=FALSE, warning=FALSE}
cor_pearson2 <- cor.sdf(x="composite", y="b017451", data=sdf_dnf, 
                        method="Pearson", weightVar="origwt")
cor_spearman2 <- cor.sdf(x="composite", y="b017451", data=sdf_dnf, 
                         method="Spearman", weightVar="origwt")
cor_polyserial2 <- cor.sdf(x="composite", y="b017451", data=sdf_dnf, 
                           method="Polyserial", weightVar="origwt")
```

```{r cor comparison2, warning=FALSE}
cbind(Correlation=c(Pearson=cor_pearson2$correlation,
                    Spearman=cor_spearman2$correlation,
                    Polyserial=cor_polyserial2$correlation))
```

## Unweighted correlations

The `cor.sdf` function also features the ability to perform correlations without accounting for weights. The `cor.sdf` function automatically accounts for the default sample weights of the NCES data set read for analysis in `weightVar="default"`, but can be modified by setting `weightVar=NULL`. The following example shows the correlation coefficients of the Pearson and Spearman methods of the variables `pared` and `b017451` while excluding weights:

```{r correlation unweighted, cache=FALSE, warning=FALSE}
cor_pearson_unweighted <- cor.sdf(x="b017451", y="pared", data=sdf,
                                  method="Pearson", weightVar=NULL)
cor_pearson_unweighted
cor_spearman_unweighted <- cor.sdf(x="b017451", y="pared", data=sdf,
                                   method="Spearman", weightVar=NULL)
cor_spearman_unweighted
```

# Subsetting the Data

A subset of a data set can be used with `EdSurvey` package functions. In this example, a summary table is created with `edsurveyTable` after filtering the sample to include only those students whose value in the `dsex` variable is Male and race (as variable `sdracem`) is either values 1 or 3 (White or Hispanic). Both value levels and labels can be used in `EdSurvey` package functions.

```{r subset, cache=FALSE, warning=FALSE}
sdfm <- subset(sdf, dsex == "Male" & (sdracem == 3 | sdracem == 1))
es2 <- edsurveyTable(composite ~ dsex + sdracem, data=sdfm)
```
```{r, eval=FALSE}
es2
```
```{r subset table, cache=FALSE, results='asis', echo=FALSE}
knitr::kable(x=es2$data, digits=7, row.names=FALSE, caption="es2")
```

# Getting a data.frame for Further Manipulation

Data can be extracted and manipulated using the function `getData`. The function `getData` takes an `edsurvey.data.frame` and returns a `light.edsurvey.data.frame` containing requested variables by either specifying a set of variable names in `varnames` or by entering a formula in `formula`.[^helpgetData]

[^helpgetData]: Consult the appendix or `?getData` for details on default `getData` arguments.


To access and manipulate all data for `dsex` and `b017451` variables in `sdf` can be returned by calling `getData`. Note that in the following code, the `head` function is used. This reveals only the first few rows of the resulting data:

```{r getData, cache=FALSE, warning=FALSE}
gddat <- getData(data=sdf, varnames=c("dsex","b017451"), omittedLevels=TRUE)
head(gddat)
```

By default, setting `omittedLevels` to `TRUE` removes special values such as multiple entries or `NA`s. `getData` tries to help by dropping the levels of factors for regression, tables, and correlations that are not typically included in analysis.

##### Merging student and school data sets

After loading the `edsurvey.data.frame` object into the R working environment, both student and school data from a NCES data set can be analyzed and merged using `getData`. To retrieve school variables, include them in the vector of variable names in the `getData` call and specify the key linking variables in the student and school data sets within the arguments `schoolMergeVarStudent` and `schoolMergeVarSchool`. In this example, `getData` calls the variables `dsex` and `b017451` from the student data file, as well as the variable `c052601` from the school data file, merging the student variable key `scrpsu` on the school variable key `sscrpsu`:

```{r getData school merge, cache=FALSE, warning=FALSE}
gddat2 <- getData(data=sdf, varnames=c("dsex","b017451","c052601"), 
                  schoolMergeVarStudent="scrpsu", schoolMergeVarSchool="sscrpsu")
head(gddat2)
```

##### Retrieving all variables in a data set

To extract *all* of the data in an `edsurvey.data.frame`, define the `varnames` argument as `names(sdf)`, which will query all variables. Setting the arguments `omittedLevels` and `defaultConditions` to `FALSE` ensures that values that would normally be removed are included:

```{r get all data, warning=FALSE}
lsdf0 <- getData(data=sdf, varnames=names(sdf), addAttributes=TRUE,
                 omittedLevels=FALSE, defaultConditions=FALSE)
dim(lsdf0) # excludes the one school variable in the sdf
dim(sdf)
```

Once retrieved, this data set can be used with all `EdSurvey` functions.

Additional details on the features of the `getData` function are included in the *Using the getData Function in EdSurvey `r packageVersion(quote(EdSurvey))` to Manipulate the NAEP Primer Data* vignette.

### Notes
##### Memory usage
Since many NCES databases have hundreds of columns and hundreds of thousand rows, the `EdSurvey` package allows users to subset data and run regressions *without* storing it in the global environment. Alternatively, the `getData` function retrieves `light.edsurvey.data.frames` into the global environment, which can be costly to memory usage.

This package uses the `LaF` package to read in only the necessary data when it is needed for an analysis. Instead of storing all of the data in memory, only some "header" information is stored as well as a link to the file in question. When the user calls a function, only the data needed for that function is read in. It works seamlessly and reduces the memory requirements for a user's machine.

##### Factors and factor analysis

R uses the concept of **factors** for data storage. This is a separate concept from factor analysis. In the case of the R storage method, it is simply a way of enforcing that valid data labels are the only labels that are used.

### Summary and next steps

This vignette covered the basics of the `EdSurvey` package, such as preparing the R environment for analysis, creating summary tables with `edsurveyTable`, running linear regression models with `lm.sdf`, correlating variables with `cor.sdf`, and retrieving data for manipulation with the `getData` function. Aspects of the package relating to memory usage also were considered.

If you are interested in manipulating the `EdSurvey` data in a similar manner as other `data.frame`s, consult the *Using the getData Function in `EdSurvey` `r packageVersion(quote(EdSurvey))` to Manipulate the NAEP Primer Data* vignette.

For a full list of `EdSurvey` functions and documentation, use the R help viewer:
```{r rhelp, eval=FALSE}
help(package="EdSurvey")
```

***

# Appendix

## 1. achievementLevels
- **achievementVars:** Character vector indicating variables to be included in the achievement levels table, potentially with a subject scale or subscale. When the subject scale or subscale is omitted, then the default subject scale or subscale is used. You can find the default composite scale and all subscales using the function `showPlausibleValues`.
- **aggregateBy:** Character vector specifying variables to aggregate achievement levels by. The percentage column sums up to 100 for all levels of all variables specified here. When set to defaut of `NULL`, the percentage column sums up to 100 for all levels of all variables specified in in `achievementVars`.
- **data****:** An `edsurvey.data.frame`.
- **cutpoints:** Numeric vector indicating cut points for *Basic*, *Proficient*, *Advanced*. Set to standard NAEP cut points by default.
- **returnDiscrete:** Logical indicating if discrete achievement levels should be returned. Defaults to `TRUE`.
- **returnCumulative:** Logical indicating if cumulative achievement levels should be returned. Defaults to `FALSE`.
- **weightVar:** Character indicating the weight variable to use.
- **jrrIMax:** Numeric value. When using the jackknife variance estimation method, the $V_{jrr}$ term can be estimated with any positive number of plausible values and is estimated on the first of the lower of the number of available plausible values and `jrrIMax`. Because of this, when `jrrIMax` is set to Inf, all of the plausible values will be used. Higher values of `jrrIMax` lead to longer computing times and more accurate variance estimates.
- **schoolMergeVarStudent:** A character variable name from the student file used to merge student and school data files. Set to `NULL` by default.
- **schoolMergeVarSchool:** A character variable name from the school file used to merge student and school data files. Set to `NULL` by default.
- **omittedLevels:** A logical value set to `TRUE` indicating that drops those levels of all factor variables that are specified in `edsurvey.data.frame`. Use `print` on an `edsurvey.data.frame` to see the omitted levels.
- **defaultConditions:** A logical value set to `TRUE` that uses the default conditions stored in `edsurvey.data.frame` to subset the data. Use `print` on an `edsurvey.data.frame` to see the default conditions.
- **recode:** A list of lists to recode variables. Defaults to `NULL`. Can be set as `recode=list(var1= list(from=c("a","b","c"), to ="d"))`. See examples using `?cor.sdf`.

## 2. cor.sdf
- **x:** A character variable name from the `data` to be correlated with `y`.
- **y:** A character variable name from the `data` to be correlated with `x`.
- **data****:** Object of class `edsurvey.data.frame`.
- **method:** Character string indicating which correlation coefficient (or covariance) is to be computed. One of "Pearson" (default), "Spearman," "Polychoric," or "Polyserial."
- **weightVar:** Character indicating the weight variable to use.
- **reorder:** A list to reorder variables. Defaults to `NULL`. Can be set as r`eorder=list(var1=c("a","b","c"), var2=c("4","3","2","1"))`. See examples using `?cor.sdf`.
- **schoolMergeVarStudent:** A character variable name from the student file used to merge student and school data files. Set to `NULL` by default.
- **schoolMergeVarSchool:** A character variable name from the school file used to merge student and school data files. Set to `NULL` by default.
- **omittedLevels:** A logical value set to `TRUE` indicating that drops those levels of all factor variables that are specified in `edsurvey.data.frame`. Use `print` on an `edsurvey.data.frame` to see the omitted levels.
- **defaultConditions:** A logical value set to `TRUE` that uses the default conditions stored in `edsurvey.data.frame` to subset the data. Use `print` on an `edsurvey.data.frame` to see the default conditions.
- **recode:** A list of lists to recode variables. Defaults to `NULL`. Can be set as `recode=list(var1= list(from=c("a","b","c"), to ="d"))`. See examples using `?cor.sdf`.

## 3. edsurveyTable
- **formula:** Object of class `formula`, potentially with a subject scale or subscale on the left hand side, and variable(s) for tabulation on the right hand side.
- **data****:** Object of class `edsurvey.data.frame`.
- **weightVar:** Character string indicating the weight variable to use, defaults to `NULL`.
- **jrrIMax:** Integer indicating the maximum number of plausible values to include when calculating the variance term. Defaults to 1.
- **pctAggregationLevel:** The percentage variable sums up to 100 for the first `pctAggregationLevel` columns. Defaults to `NULL`.
- **returnMeans:** A logical value set to `TRUE` to get the `MEAN` and `SE(MEAN)` columns in the returned table.
- **returnSepct:** A logical value set to `TRUE` to get the `SEPCT` column in the returned table.
- **drop:** A logical value set to `FALSE` indicating that when a single column is returned, it is still represented as a `data.frame` and is not converted to a vector.
- **schoolMergeVarStudent:** A character variable name from the student file used to merge student and school data files. Set to `NULL` by default.
- **schoolMergeVarSchool:** A character variable name from the school file used to merge student and school data files. Set to `NULL` by default.
- **omittedLevels:** A logical value set to `TRUE` indicating that drops those levels of all factor variables that are specified in `edsurvey.data.frame`. Use `print` on an `edsurvey.data.frame` to see the omitted levels.
- **defaultConditions:** A logical value set to `TRUE` that uses the default conditions stored in `edsurvey.data.frame` to subset the data. Use `print` on an `edsurvey.data.frame` to see the default conditions.
- **recode:** A list of lists to recode variables. Defaults to `NULL`. Can be set as `recode=list(var1= list(from=c("a","b","c"), to ="d"))`. See examples using `?getData`.

## 4. getData
- **data****:** Object of class `edsurvey.data.frame`.
- **varnames:** A character vector of variable names that will be returned. When both `varnames` and a `formula` are specified, variables associated with both are returned. Set to `NULL` by default.
- **drop:** A logical value set to `FALSE` indicating that when a single column is returned, it is still represented as a `data.frame` and is not converted to a vector.
- **schoolMergeVarStudent:** A character variable name from the student file used to merge student and school data files. Set to `NULL` by default.
- **schoolMergeVarSchool:** A character variable name from the school file used to merge student and school data files. Set to `NULL` by default.
- **dropUnusedLevels:** A logical value set to `TRUE` that drops unused levels of all factor variables.
- **omittedLevels:** A logical value set to `TRUE` indicating that drops those levels of all factor variables that are specified in `edsurvey.data.frame`. Use `print` on an `edsurvey.data.frame` to see the omitted levels.
- **defaultConditions:** A logical value set to `TRUE` that uses the default conditions stored in `edsurvey.data.frame` to subset the data. Use `print` on an `edsurvey.data.frame` to see the default conditions.
- **formula:** A `formula`. When included, `getData` returns data associated with all variables of the `formula`. When both `varname` and a `formula` are specified, the variables associated with both are returned. Set to `NULL` by default.
- **recode:** A list of lists to recode variables. Defaults to `NULL`. Can be set as `recode=list(var1= list(from=c("a","b","c"), to ="d"))`. See examples using `?getData`.
- **includeNaLabel:** A logical value that when set to `TRUE` returns literal `NA` values. When set to `FALSE` (the default), it returns factor levels coded as `NA`.
- **addAttributes:** A logical value set to `TRUE` that returns a `light.edsurvey.data.frame` for use in calls to other functions that usually would require an `edsurvey.data.frame`.
- **returnJKreplicates:** A logical value indicating if jackknife replicate weights be returned. Defaults to `TRUE`.

## 5. lm.sdf
- **formula:** Object of class `formula`, potentially with a subject scale or subscale on the left hand side, and variable(s) for tabulation on the right hand side.
- **data****:** Object of class `edsurvey.data.frame`.
- **weightVar:** Character indicating the weight variable to use.
- **relevels:** Object of class list. Used to change the contrasts from the default treatment contrasts to treatment contrasts with a chosen omitted group, defaults to `NULL`. See examples using `?lm.sdf`.
- **varMethod:** A character set to "jackknife" or "Taylor" that indicates the variance estimation method to be used.
- **jrrIMax:** Integer indicating the maximum number of plausible values to include when calculating the variance term, defaults to 1.
- **schoolMergeVarStudent:** A character variable name from the student file used to merge student and school data files. Set to `NULL` by default.
- **schoolMergeVarSchool:** A character variable name from the school file used to merge student and school data files. Set to `NULL` by default.
- **omittedLevels:** A logical value set to `TRUE` indicating that drops those levels of all factor variables that are specified in `edsurvey.data.frame`. Use `print` on an `edsurvey.data.frame` to see the omitted levels.
- **defaultConditions:** A logical value set to `TRUE` that uses the default conditions stored in `edsurvey.data.frame` to subset the data. Use `print` on an `edsurvey.data.frame` to see the default conditions.
- **recode:** A list of lists to recode variables. Defaults to `NULL`. Can be set as `recode=list(var1= list(from=c("a","b","c"), to ="d"))`. See examples using `?getData`.
